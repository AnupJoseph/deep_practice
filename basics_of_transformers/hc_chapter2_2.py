# -*- coding: utf-8 -*-
"""HC_chapter2.2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18gVmzSr5PDs63CVdtSB3lCsVAcsZXZty
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForSequenceClassification
from rich import print

# %load_ext rich

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding = True, truncation=True, return_tensors = "pt")
inputs

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)

outputs = model(**inputs)
outputs.last_hidden_state.shape

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)
outputs.logits.shape

outputs.logits

prediction = torch.nn.functional.softmax(outputs.logits, dim=-1)
prediction

model.config.id2label

